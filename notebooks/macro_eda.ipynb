{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "project_root = os.getenv('PROJECT_ROOT')\n",
    "\n",
    "# Define the path to the raw macro data\n",
    "macro_raw_path = os.path.join(project_root, 'data', 'raw', 'macro_data.csv')\n",
    "\n",
    "# Read the CSV file\n",
    "macro_df = pd.read_csv(macro_raw_path, parse_dates=['date'])\n",
    "\n",
    "# Set 'date' as the index and ensure it's datetime\n",
    "macro_df.set_index('date', inplace=True)\n",
    "macro_df.index = pd.to_datetime(macro_df.index)\n",
    "\n",
    "# Convert object types to numeric types\n",
    "macro_df = macro_df.infer_objects()\n",
    "\n",
    "# Alternatively, explicitly convert columns to numeric\n",
    "for column in macro_df.columns:\n",
    "    macro_df[column] = pd.to_numeric(macro_df[column], errors='coerce')\n",
    "\n",
    "# Interpolate missing values using the time method\n",
    "macro_df.interpolate(method='time', inplace=True)\n",
    "\n",
    "# Forward-fill any remaining missing values\n",
    "macro_df.ffill(inplace=True)\n",
    "\n",
    "# Now you can proceed with resampling or further processing\n",
    "# For example, resample to monthly frequency\n",
    "macro_monthly_df = macro_df.resample('ME').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP         float64\n",
      "CPIAUCSL    float64\n",
      "UNRATE      float64\n",
      "FEDFUNDS    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(macro_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                GDP  CPIAUCSL  UNRATE  FEDFUNDS\n",
      "date                                           \n",
      "1946-01-01      NaN       NaN     NaN       NaN\n",
      "1946-04-01      NaN       NaN     NaN       NaN\n",
      "1946-07-01      NaN       NaN     NaN       NaN\n",
      "1946-10-01      NaN       NaN     NaN       NaN\n",
      "1947-01-01  243.164     21.48     NaN       NaN\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 938 entries, 1946-01-01 to 2024-10-01\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   GDP       934 non-null    float64\n",
      " 1   CPIAUCSL  934 non-null    float64\n",
      " 2   UNRATE    922 non-null    float64\n",
      " 3   FEDFUNDS  844 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 36.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(macro_df.head())\n",
    "print(macro_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the processed data\n",
    "processed_data_dir = os.path.join(project_root, 'data', 'processed')\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "# Save the processed macro data\n",
    "macro_processed_path = os.path.join(processed_data_dir, 'macro_data_processed.csv')\n",
    "macro_monthly_df.to_csv(macro_processed_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Billing        Region\n",
      "Date                               \n",
      "1986-01-01   555850.0      Americas\n",
      "1986-01-01   346467.0        Europe\n",
      "1986-01-01   638547.0         Japan\n",
      "1986-01-01   105050.0  Asia Pacific\n",
      "1986-01-01  1645914.0     Worldwide\n",
      "Billing    float64\n",
      "Region      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the processed billing data\n",
    "billing_processed_path = os.path.join(processed_data_dir, 'global_billings_processed.csv')\n",
    "\n",
    "# Load the billing data\n",
    "billing_df = pd.read_csv(billing_processed_path, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Inspect the DataFrame\n",
    "print(billing_df.head())\n",
    "print(billing_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that macro_monthly_df has 'Date' as index\n",
    "macro_monthly_df.index.name = 'Date'\n",
    "\n",
    "# Align indices\n",
    "billing_df.index = pd.to_datetime(billing_df.index)\n",
    "macro_monthly_df.index = pd.to_datetime(macro_monthly_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in left dataset; not a one-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merge DataFrames\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbilling_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmacro_monthly_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mone_to_one\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Inspect the combined DataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\ehbai\\Documents\\chips\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\ehbai\\Documents\\chips\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:813\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_validate_kwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ehbai\\Documents\\chips\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1653\u001b[0m, in \u001b[0;36m_MergeOperation._validate_validate_kwd\u001b[1;34m(self, validate)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in either left \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor right dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1651\u001b[0m     )\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left_unique:\n\u001b[1;32m-> 1653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in left dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1655\u001b[0m     )\n\u001b[0;32m   1656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_unique:\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1658\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in right dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1659\u001b[0m     )\n",
      "\u001b[1;31mMergeError\u001b[0m: Merge keys are not unique in left dataset; not a one-to-one merge"
     ]
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "combined_df = pd.merge(billing_df, macro_monthly_df, left_index=True, right_index=True, how='inner', validate='one_to_one', on=None)\n",
    "\n",
    "\n",
    "\n",
    "# Inspect the combined DataFrame\n",
    "print(combined_df.head())\n",
    "print(combined_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "# Handle missing values as appropriate\n",
    "combined_df = combined_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Now 'Worldwide' should be a column\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(combined_df.index, combined_df['Worldwide'], label='Worldwide Billings')\n",
    "plt.title('Worldwide Semiconductor Billings Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Billings (in millions)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
